{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee30038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benja\\Documents\\Universidad\\2025-2\\Recomendadores\\Proyecto\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import implicit\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba1471",
   "metadata": {},
   "source": [
    "# Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0981800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "animes = pd.read_csv('data/animes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df01e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2052</td>\n",
       "      <td>12445.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5141</td>\n",
       "      <td>34599.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3340</td>\n",
       "      <td>37510.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588</td>\n",
       "      <td>853.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4822</td>\n",
       "      <td>27775.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid   itemid  rating\n",
       "0    2052  12445.0       1\n",
       "1    5141  34599.0       1\n",
       "2    3340  37510.0       1\n",
       "3     588    853.0       1\n",
       "4    4822  27775.0       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"train\", sep=\",\", names=[\"userid\", \"itemid\", \"rating\"], header=None\n",
    ")\n",
    "\n",
    "df_train.rating = [1 if x >= 5 else 0 for x in df_train.rating]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f077fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18887</td>\n",
       "      <td>37450.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8831</td>\n",
       "      <td>32379.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37283</td>\n",
       "      <td>36882.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35602</td>\n",
       "      <td>10490.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid   itemid  rating\n",
       "0   18887  37450.0      10\n",
       "1    8831  32379.0       2\n",
       "2   37283  36882.0       9\n",
       "3   35602  10490.0       9\n",
       "4   39042      NaN       6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"test\", sep=\",\", names=[\"userid\", \"itemid\", \"rating\"], header=None\n",
    ")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abd6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_interaction_counts = df_train['itemid'].value_counts()\n",
    "user_count = df_train['userid'].nunique()\n",
    "item_popularity = (item_interaction_counts / user_count).to_dict()\n",
    "metadata = animes[['uid', 'genre']]\n",
    "item_categories: dict[int, set[str | None]] = {}\n",
    "for row in metadata.itertuples():\n",
    "    item_categories[int(row[1]) if row[1].is_integer() else row[1]] = set(map(lambda i: i.strip(), row[2].split(','))) if isinstance(row[2], str) else set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8140f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nan items\n",
    "df_train = df_train.dropna(subset=['itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e7b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = {}\n",
    "itemset = set()\n",
    "\n",
    "for row in df_train.itertuples():\n",
    "    if row[1] not in user_items:\n",
    "        user_items[row[1]] = []\n",
    "\n",
    "    user_items[row[1]].append(row[2])\n",
    "    itemset.add(row[2])\n",
    "\n",
    "itemset = np.sort(list(itemset))\n",
    "\n",
    "sparse_matrix = np.zeros((len(user_items), len(itemset)))\n",
    "\n",
    "for i, items in enumerate(user_items.values()):\n",
    "    sparse_matrix[i] = np.isin(itemset, items, assume_unique=True).astype(int)\n",
    "\n",
    "matrix = sp.csr_matrix(sparse_matrix.T)\n",
    "\n",
    "user_item_matrix = matrix.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b698c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import precision_at_k, ndcg_at_k, novelty, diversity, recall_at_k, average_precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e847170",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2row = {user_id: matrix_row for matrix_row, user_id in enumerate(user_items.keys())}\n",
    "row2user = {matrix_row: user_id for user_id, matrix_row in user2row.items()}\n",
    "\n",
    "item2col = {item_id: matrix_col for matrix_col, item_id in enumerate(itemset)}\n",
    "col2item = {matrix_col: item_id for item_id, matrix_col in item2col.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c4723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_test = {}\n",
    "\n",
    "for row in df_test.itertuples():\n",
    "    if row[1] not in user_items_test:\n",
    "        user_items_test[row[1]] = []\n",
    "\n",
    "    user_items_test[row[1]].append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a252361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benja\\Documents\\Universidad\\2025-2\\Recomendadores\\Proyecto\\.venv\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    }
   ],
   "source": [
    "model_als = implicit.als.AlternatingLeastSquares(factors=300)\n",
    "model_als.fit(user_item_matrix, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(n, user_groups, delta=0.05):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo calculando métricas globales y de fairness.\n",
    "    \n",
    "    Args:\n",
    "        n (int): El 'k' para las métricas @k.\n",
    "        user_groups (dict): {user_id: 'group_label'}\n",
    "        delta (float): Umbral de disparidad para considerar \"sesgado\".\n",
    "    \"\"\"\n",
    "    \n",
    "    group_scores = {\n",
    "        'recall': {},  \n",
    "        'precision': {} \n",
    "    }\n",
    "    \n",
    "    all_recalls = []\n",
    "    all_aps = []\n",
    "    all_ndcgs = []\n",
    "    all_novelties = []\n",
    "    all_diversities = []\n",
    "    all_precisions = []\n",
    "    \n",
    "    for user_id in user_items_test.keys():\n",
    "        \n",
    "        # 1. Obtener datos del usuario\n",
    "        if user_id not in user_groups:\n",
    "            continue\n",
    "        \n",
    "        if user_id not in user2row:\n",
    "            continue\n",
    "            \n",
    "        group = user_groups[user_id]\n",
    "        truth_items = user_items_test.get(user_id, set())\n",
    "        \n",
    "        # 2. Obtener recomendaciones y vector de relevancia\n",
    "        user_row = user2row[user_id]\n",
    "        \n",
    "        rec = model_als.recommend(user_row, user_item_matrix[user_row], n)[0]\n",
    "        rec = np.array([col2item[col] for col in rec])\n",
    "        \n",
    "        rel_vector = np.isin(rec, truth_items, assume_unique=True).astype(int)\n",
    "\n",
    "        # 3. Calcular métricas individuales\n",
    "        user_recall = recall_at_k(rel_vector, n)\n",
    "        user_precision = precision_at_k(rel_vector, n)\n",
    "        user_ap = average_precision_at_k(rel_vector, n)\n",
    "        user_ndcg = ndcg_at_k(rel_vector, n)\n",
    "        user_novelty = novelty(rec, item_popularity)\n",
    "        user_diversity = diversity(rec, n, item_categories)\n",
    "\n",
    "        # 4. Almacenar para métricas globales\n",
    "        all_recalls.append(user_recall)\n",
    "        all_precisions.append(user_precision)\n",
    "        all_aps.append(user_ap)\n",
    "        all_ndcgs.append(user_ndcg)\n",
    "        all_novelties.append(user_novelty)\n",
    "        all_diversities.append(user_diversity)\n",
    "\n",
    "        # 5. Almacenar métricas de fairness por grupo\n",
    "        if group not in group_scores['recall']:\n",
    "            group_scores['recall'][group] = []\n",
    "            group_scores['precision'][group] = []\n",
    "            \n",
    "        group_scores['recall'][group].append(user_recall)\n",
    "        group_scores['precision'][group].append(user_precision)\n",
    "\n",
    "    # --- 6. Calcular Métricas Promedio (Globales) ---\n",
    "    \n",
    "    metrics_global = {\n",
    "        'mean_recall': np.mean(all_recalls) if all_recalls else 0.0,\n",
    "        'mean_precision': np.mean(all_precisions) if all_precisions else 0.0,\n",
    "        'mean_ap (MAP)': np.mean(all_aps) if all_aps else 0.0,\n",
    "        'mean_ndcg': np.mean(all_ndcgs) if all_ndcgs else 0.0,\n",
    "        'mean_novelty': np.mean(all_novelties) if all_novelties else 0.0,\n",
    "        'mean_diversity': np.mean(all_diversities) if all_diversities else 0.0,\n",
    "        'num_users_evaluated': len(all_recalls)\n",
    "    }\n",
    "    \n",
    "    # --- 7. Calcular Métricas de Fairness (Disparidad) ---\n",
    "    \n",
    "    fairness_report = {\n",
    "        'delta_threshold': delta,\n",
    "        'is_biased_recall': 0,\n",
    "        'is_biased_precision': 0,\n",
    "        'group_averages': {},\n",
    "        'disparity_reports': []\n",
    "    }\n",
    "\n",
    "    avg_recall_group = {g: np.mean(s) for g, s in group_scores['recall'].items() if s}\n",
    "    avg_precision_group = {g: np.mean(s) for g, s in group_scores['precision'].items() if s}\n",
    "    \n",
    "    fairness_report['group_averages'] = {\n",
    "        g: {\n",
    "            'recall (Cobertura)': avg_recall_group.get(g, 0.0),\n",
    "            'precision (Tasa Aceptación)': avg_precision_group.get(g, 0.0),\n",
    "            'count': len(group_scores['recall'].get(g, []))\n",
    "        } for g in avg_recall_group.keys()\n",
    "    }\n",
    "\n",
    "    # Comparar pares de grupos\n",
    "    group_names = list(avg_recall_group.keys())\n",
    "    for i in range(len(group_names)):\n",
    "        for j in range(i + 1, len(group_names)):\n",
    "            g_a = group_names[i]\n",
    "            g_b = group_names[j]\n",
    "            \n",
    "            r_a, r_b = avg_recall_group[g_a], avg_recall_group[g_b]\n",
    "            abs_disp_recall = abs(r_a - r_b)\n",
    "            \n",
    "            p_a, p_b = avg_precision_group[g_a], avg_precision_group[g_b]\n",
    "            abs_disp_precision = abs(p_a - p_b)\n",
    "\n",
    "            pair_report = {\n",
    "                'pair': (g_a, g_b),\n",
    "                'recall_disparity': abs_disp_recall,\n",
    "                'precision_disparity': abs_disp_precision,\n",
    "                'biased_recall (Cobertura)': 1 if abs_disp_recall > delta else 0,\n",
    "                'biased_precision (Tasa Aceptación)': 1 if abs_disp_precision > delta else 0\n",
    "            }\n",
    "            fairness_report['disparity_reports'].append(pair_report)\n",
    "            \n",
    "            if abs_disp_recall > delta:\n",
    "                fairness_report['is_biased_recall'] = 1\n",
    "            if abs_disp_precision > delta:\n",
    "                fairness_report['is_biased_precision'] = 1\n",
    "    \n",
    "    return metrics_global, fairness_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44a77dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthday</th>\n",
       "      <th>favorites_anime</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DesolatePsyche</td>\n",
       "      <td>Male</td>\n",
       "      <td>Oct 2, 1994</td>\n",
       "      <td>['33352', '25013', '5530', '33674', '1482', '2...</td>\n",
       "      <td>https://myanimelist.net/profile/DesolatePsyche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baekbeans</td>\n",
       "      <td>Female</td>\n",
       "      <td>Nov 10, 2000</td>\n",
       "      <td>['11061', '31964', '853', '20583', '918', '925...</td>\n",
       "      <td>https://myanimelist.net/profile/baekbeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['918', '2904', '11741', '17074', '23273', '32...</td>\n",
       "      <td>https://myanimelist.net/profile/skrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edgewalker00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sep 5</td>\n",
       "      <td>['5680', '849', '2904', '3588', '37349']</td>\n",
       "      <td>https://myanimelist.net/profile/edgewalker00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aManOfCulture99</td>\n",
       "      <td>Male</td>\n",
       "      <td>Oct 30, 1999</td>\n",
       "      <td>['4181', '7791', '9617', '5680', '2167', '4382...</td>\n",
       "      <td>https://myanimelist.net/profile/aManOfCulture99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           profile  gender      birthday  \\\n",
       "0   DesolatePsyche    Male   Oct 2, 1994   \n",
       "1        baekbeans  Female  Nov 10, 2000   \n",
       "2             skrn     NaN           NaN   \n",
       "3     edgewalker00    Male         Sep 5   \n",
       "4  aManOfCulture99    Male  Oct 30, 1999   \n",
       "\n",
       "                                     favorites_anime  \\\n",
       "0  ['33352', '25013', '5530', '33674', '1482', '2...   \n",
       "1  ['11061', '31964', '853', '20583', '918', '925...   \n",
       "2  ['918', '2904', '11741', '17074', '23273', '32...   \n",
       "3           ['5680', '849', '2904', '3588', '37349']   \n",
       "4  ['4181', '7791', '9617', '5680', '2167', '4382...   \n",
       "\n",
       "                                              link  \n",
       "0   https://myanimelist.net/profile/DesolatePsyche  \n",
       "1        https://myanimelist.net/profile/baekbeans  \n",
       "2             https://myanimelist.net/profile/skrn  \n",
       "3     https://myanimelist.net/profile/edgewalker00  \n",
       "4  https://myanimelist.net/profile/aManOfCulture99  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles = pd.read_csv('data/profiles.csv')\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "929a1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"data/reviews.csv\")\n",
    "\n",
    "# Assign a unique id to each username\n",
    "unique_users = reviews[\"username\"].unique()\n",
    "user_mapping = {user: i for i, user in enumerate(unique_users)}\n",
    "reviews[\"user_id\"] = reviews[\"username\"].map(user_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b15ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles[\"user_id\"] = profiles[\"profile\"].map(user_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52123e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Métricas Globales de Evaluación ---\n",
      "{\n",
      "  \"mean_recall\": 0.02736883066346715,\n",
      "  \"mean_precision\": 0.0030352162915883002,\n",
      "  \"mean_ap (MAP)\": 0.012203687061005953,\n",
      "  \"mean_ndcg\": 0.015884514594982833,\n",
      "  \"mean_novelty\": 8.479939905283517,\n",
      "  \"mean_diversity\": 0.909071042154162,\n",
      "  \"num_users_evaluated\": 15419\n",
      "}\n",
      "\n",
      "--- Reporte de Fairness (Disparidad de Grupo) ---\n",
      "{\n",
      "  \"delta_threshold\": 0.05,\n",
      "  \"is_biased_recall\": 0,\n",
      "  \"is_biased_precision\": 0,\n",
      "  \"group_averages\": {\n",
      "    \"NaN\": {\n",
      "      \"recall (Cobertura)\": 0.023988615572270788,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.002663142915226672,\n",
      "      \"count\": 4919\n",
      "    },\n",
      "    \"Female\": {\n",
      "      \"recall (Cobertura)\": 0.02261985145172181,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.0023970290344361915,\n",
      "      \"count\": 2962\n",
      "    },\n",
      "    \"Male\": {\n",
      "      \"recall (Cobertura)\": 0.03133864649466433,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.003525597730649737,\n",
      "      \"count\": 7403\n",
      "    },\n",
      "    \"Non-Binary\": {\n",
      "      \"recall (Cobertura)\": 0.037037037037037035,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.003703703703703704,\n",
      "      \"count\": 135\n",
      "    }\n",
      "  },\n",
      "  \"disparity_reports\": [\n",
      "    {\n",
      "      \"pair\": [\n",
      "        NaN,\n",
      "        \"Female\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.0013687641205489785,\n",
      "      \"precision_disparity\": 0.0002661138807904806,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        NaN,\n",
      "        \"Male\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.0073500309223935405,\n",
      "      \"precision_disparity\": 0.0008624548154230649,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        NaN,\n",
      "        \"Non-Binary\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.013048421464766247,\n",
      "      \"precision_disparity\": 0.0010405607884770318,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        \"Female\",\n",
      "        \"Male\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.008718795042942519,\n",
      "      \"precision_disparity\": 0.0011285686962135455,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        \"Female\",\n",
      "        \"Non-Binary\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.014417185585315226,\n",
      "      \"precision_disparity\": 0.0013066746692675124,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        \"Male\",\n",
      "        \"Non-Binary\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.005698390542372707,\n",
      "      \"precision_disparity\": 0.00017810597305396685,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Recall Global: 0.0274\n",
      "MAP Global: 0.0122\n",
      "¿Es sesgado (Recall)?: 0\n",
      "¿Es sesgado (Precision)?: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "user_groups_map = {}\n",
    "# user_groups_map id a sexo\n",
    "for row in profiles.itertuples():\n",
    "    user_id = row.user_id\n",
    "    user_groups_map[user_id] = row.gender\n",
    "\n",
    "K = 10\n",
    "DELTA_FAIRNESS = 0.05\n",
    "\n",
    "global_metrics, fairness_results = evaluate_model(K, user_groups_map, DELTA_FAIRNESS)\n",
    "\n",
    "print(\"--- Métricas Globales de Evaluación ---\")\n",
    "print(json.dumps(global_metrics, indent=2))\n",
    "\n",
    "print(\"\\n--- Reporte de Fairness (Disparidad de Grupo) ---\")\n",
    "print(json.dumps(fairness_results, indent=2))\n",
    "\n",
    "print(f\"\\nRecall Global: {global_metrics['mean_recall']:.4f}\")\n",
    "print(f\"MAP Global: {global_metrics['mean_ap (MAP)']:.4f}\")\n",
    "print(f\"¿Es sesgado (Recall)?: {fairness_results['is_biased_recall']}\")\n",
    "print(f\"¿Es sesgado (Precision)?: {fairness_results['is_biased_precision']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
