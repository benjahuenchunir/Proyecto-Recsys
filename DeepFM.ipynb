{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr_torch.inputs import SparseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics_header",
   "metadata": {},
   "source": [
    "# Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "animes = pd.read_csv('clean_data/animes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_train",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14179</td>\n",
       "      <td>13601.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37548</td>\n",
       "      <td>34300.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>796</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3041</td>\n",
       "      <td>949.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2493</td>\n",
       "      <td>5114.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid   itemid  rating\n",
       "0   14179  13601.0       1\n",
       "1   37548  34300.0       1\n",
       "2     796   2592.0       0\n",
       "3    3041    949.0       1\n",
       "4    2493   5114.0       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"train\", sep=\",\", names=[\"userid\", \"itemid\", \"rating\"], header=None\n",
    ")\n",
    "\n",
    "# Convert ratings to binary target (1 if >= 5 else 0)\n",
    "df_train.rating = [1 if x >= 5 else 0 for x in df_train.rating]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_test",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506</td>\n",
       "      <td>37517.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16392</td>\n",
       "      <td>7311.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>553</td>\n",
       "      <td>12471.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13348</td>\n",
       "      <td>8937.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276</td>\n",
       "      <td>35997.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid   itemid  rating\n",
       "0     506  37517.0      10\n",
       "1   16392   7311.0       9\n",
       "2     553  12471.0       5\n",
       "3   13348   8937.0       6\n",
       "4     276  35997.0       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"test\", sep=\",\", names=[\"userid\", \"itemid\", \"rating\"], header=None\n",
    ")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prep_metrics_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_interaction_counts = df_train['itemid'].value_counts()\n",
    "user_count = df_train['userid'].nunique()\n",
    "item_popularity = (item_interaction_counts / user_count).to_dict()\n",
    "metadata = animes[['uid', 'genre']]\n",
    "item_categories: dict[int, set[str | None]] = {}\n",
    "for row in metadata.itertuples():\n",
    "    item_categories[int(row[1]) if hasattr(row[1], 'is_integer') and row[1].is_integer() else row[1]] = set(map(lambda i: i.strip(), row[2].split(','))) if isinstance(row[2], str) else set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clean_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=['itemid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deepfm_encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "lbe_user = LabelEncoder()\n",
    "data['userid_enc'] = lbe_user.fit_transform(data['userid'])\n",
    "\n",
    "lbe_item = LabelEncoder()\n",
    "data['itemid_enc'] = lbe_item.fit_transform(data['itemid'])\n",
    "\n",
    "train = data.iloc[:len(df_train)].copy()\n",
    "test = data.iloc[len(df_train):].copy()\n",
    "\n",
    "feature_columns = [\n",
    "    SparseFeat(\"userid_enc\", vocabulary_size=data['userid_enc'].max() + 1, embedding_dim=16),\n",
    "    SparseFeat(\"itemid_enc\", vocabulary_size=data['itemid_enc'].max() + 1, embedding_dim=16)\n",
    "]\n",
    "\n",
    "linear_feature_columns = feature_columns\n",
    "dnn_feature_columns = feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns)\n",
    "\n",
    "train_model_input = {name: train[name].values for name in feature_names}\n",
    "test_model_input = {name: test[name].values for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deepfm_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 139689 samples, validate on 0 samples, 546 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 168.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3s - loss:  0.2916 - binary_crossentropy:  0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 166.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "3s - loss:  0.1886 - binary_crossentropy:  0.1885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 164.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "3s - loss:  0.1587 - binary_crossentropy:  0.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 168.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "3s - loss:  0.1460 - binary_crossentropy:  0.1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 169.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "3s - loss:  0.1390 - binary_crossentropy:  0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 173.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "3s - loss:  0.1289 - binary_crossentropy:  0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 173.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "3s - loss:  0.1153 - binary_crossentropy:  0.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 156.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "3s - loss:  0.1026 - binary_crossentropy:  0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 165.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "3s - loss:  0.0928 - binary_crossentropy:  0.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 165.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "3s - loss:  0.0860 - binary_crossentropy:  0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 155.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "3s - loss:  0.0804 - binary_crossentropy:  0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 143.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "3s - loss:  0.0743 - binary_crossentropy:  0.0740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 159.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "3s - loss:  0.0686 - binary_crossentropy:  0.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 167.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "3s - loss:  0.0627 - binary_crossentropy:  0.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [00:03, 169.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "3s - loss:  0.0571 - binary_crossentropy:  0.0568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary', device=device)\n",
    "\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(train_model_input, train['rating'].values, batch_size=256, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prep_inference",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_test = {}\n",
    "for row in df_test.itertuples():\n",
    "    if row.userid not in user_items_test:\n",
    "        user_items_test[row.userid] = []\n",
    "    user_items_test[row.userid].append(row.itemid)\n",
    "\n",
    "all_items_enc = data['itemid_enc'].unique()\n",
    "enc_to_raw_item = {enc: raw for enc, raw in zip(data['itemid_enc'], data['itemid'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "get_recs_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, n):\n",
    "    try:\n",
    "        user_enc = lbe_user.transform([user_id])[0]\n",
    "    except ValueError:\n",
    "        return np.array([])\n",
    "\n",
    "    # Create input for ALL items for this user\n",
    "    user_enc_col = np.full(len(all_items_enc), user_enc)\n",
    "    \n",
    "    pred_input = {\n",
    "        \"userid_enc\": user_enc_col,\n",
    "        \"itemid_enc\": all_items_enc\n",
    "    }\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(pred_input, batch_size=4096).flatten()\n",
    "    \n",
    "    # Rank\n",
    "    top_indices = preds.argsort()[-n:][::-1]\n",
    "    top_enc_items = all_items_enc[top_indices]\n",
    "    \n",
    "    recommendations = [enc_to_raw_item.get(i) for i in top_enc_items]\n",
    "    return np.array(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluando usuarios: 100%|██████████| 18591/18591 [08:15<00:00, 37.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Métricas Globales de Evaluación ---\n",
      "{\n",
      "  \"mean_recall\": 0.005895313523491931,\n",
      "  \"mean_precision\": 0.0006014410766390759,\n",
      "  \"mean_ap (MAP)\": 0.004141984708292098,\n",
      "  \"mean_ndcg\": 0.0045512555422333465,\n",
      "  \"mean_novelty\": 11.431537039791108,\n",
      "  \"mean_diversity\": 0.9437161979092131,\n",
      "  \"num_users_evaluated\": 16793\n",
      "}\n",
      "\n",
      "--- Reporte de Fairness (Disparidad de Grupo) ---\n",
      "{\n",
      "  \"delta_threshold\": 0.05,\n",
      "  \"is_biased_recall\": 0,\n",
      "  \"is_biased_precision\": 0,\n",
      "  \"group_averages\": {\n",
      "    \"Male\": {\n",
      "      \"recall (Cobertura)\": 0.006072623621266576,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.0006196554715578138,\n",
      "      \"count\": 8069\n",
      "    },\n",
      "    \"NaN\": {\n",
      "      \"recall (Cobertura)\": 0.004893077201884741,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.0005074302283436029,\n",
      "      \"count\": 5518\n",
      "    },\n",
      "    \"Non-Binary\": {\n",
      "      \"recall (Cobertura)\": 0.021897810218978103,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.0021897810218978104,\n",
      "      \"count\": 137\n",
      "    },\n",
      "    \"Female\": {\n",
      "      \"recall (Cobertura)\": 0.006516780710329097,\n",
      "      \"precision (Tasa Aceptaci\\u00f3n)\": 0.0006516780710329097,\n",
      "      \"count\": 3069\n",
      "    }\n",
      "  },\n",
      "  \"disparity_reports\": [\n",
      "    {\n",
      "      \"pair\": [\n",
      "        \"Male\",\n",
      "        NaN\n",
      "      ],\n",
      "      \"recall_disparity\": 0.0011795464193818349,\n",
      "      \"precision_disparity\": 0.0001122252432142109,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        \"Male\",\n",
      "        \"Non-Binary\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.015825186597711528,\n",
      "      \"precision_disparity\": 0.0015701255503399966,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        \"Male\",\n",
      "        \"Female\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.0004441570890625218,\n",
      "      \"precision_disparity\": 3.2022599475095906e-05,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        NaN,\n",
      "        \"Non-Binary\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.017004733017093362,\n",
      "      \"precision_disparity\": 0.0016823507935542076,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        NaN,\n",
      "        \"Female\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.0016237035084443567,\n",
      "      \"precision_disparity\": 0.0001442478426893068,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    },\n",
      "    {\n",
      "      \"pair\": [\n",
      "        \"Non-Binary\",\n",
      "        \"Female\"\n",
      "      ],\n",
      "      \"recall_disparity\": 0.015381029508649006,\n",
      "      \"precision_disparity\": 0.0015381029508649007,\n",
      "      \"biased_recall (Cobertura)\": 0,\n",
      "      \"biased_precision (Tasa Aceptaci\\u00f3n)\": 0\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Recall Global: 0.0059\n",
      "MAP Global: 0.0041\n",
      "¿Es sesgado (Recall)?: 0\n",
      "¿Es sesgado (Precision)?: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluate import get_metrics\n",
    "\n",
    "get_metrics(user_items_test, item_popularity, item_categories, get_recommendations, k=10, delta=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
